# ğŸ§  Thread-Aware Conversational AI Chatbot using LangGraph and Gemini

A context-aware chatbot built using **LangGraph** and **Gemini 2.0 Flash** that maintains conversation memory based on a unique `thread_id`, enabling personalized, multi-turn interactions. Integrated with a **Streamlit** frontend for real-time chat visualization.

---

## ğŸš€ Features

- ğŸ’¬ **Multi-turn conversations** with session-level memory
- ğŸ§  **Thread-specific context** retention using `thread_id`
- âš™ï¸ **LangGraph-powered agent workflow** with state management
- ğŸŒ **Gemini 2.0 Flash** used as the LLM backbone
- ğŸ“Š **Streamlit UI** for interactive chat simulation
- ğŸ’¾ In-memory checkpointing via `InMemorySaver` for simplicity

---

## ğŸ“ Project Structure

chatbot/
â”‚
â”œâ”€â”€ chatbot.py # LangGraph backend workflow
â”œâ”€â”€ app.py # Streamlit frontend
â”œâ”€â”€ .env # API keys and environment variables
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md # Project documentation
